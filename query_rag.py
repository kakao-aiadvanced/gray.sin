from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from load_blogs import get_retriever  # ì‹¤ì œ retriever ì‚¬ìš©
from operator import itemgetter

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# JsonOutputParser ì´ˆê¸°í™”
parser = JsonOutputParser()

# 1. ê´€ë ¨ì„± í‰ê°€ PromptTemplate ì •ì˜
relevance_prompt = PromptTemplate(
    template="""You are an expert in evaluating the relevance between a user query and a retrieved document chunk.
Your task is to determine if the retrieved chunk is relevant to the user's query.
Output your answer in JSON format, using the following structure:
{{"relevance": "yes"}} if the chunk is relevant, or {{"relevance": "no"}} if it is not.

User Query: {user_query}
Retrieved Chunk: {retrieved_chunk}
{format_instructions}
""",
    input_variables=["user_query", "retrieved_chunk"],
    partial_variables={
        "format_instructions": parser.get_format_instructions()
    },
)

# ê´€ë ¨ì„± í‰ê°€ ì²´ì¸
relevance_chain = relevance_prompt | llm | parser

# 2. ë‹µë³€ ìƒì„± PromptTemplate ì •ì˜
answer_generation_prompt = PromptTemplate(
    template="""Answer the user query based on the provided context.
If the context does not contain enough information to answer the query, state that you cannot answer based on the provided context.
Context: {context}
User Query: {user_query}
Output your answer in JSON format, using the following structure: {{"answer": "Your answer here"}}.
{format_instructions}
""",
    input_variables=["user_query", "context"],
    partial_variables={
        "format_instructions": parser.get_format_instructions()
    },
)

# ë‹µë³€ ìƒì„± ì²´ì¸
answer_generation_chain = answer_generation_prompt | llm | parser

# 3. Hallucination í‰ê°€ PromptTemplate ì •ì˜
hallucination_prompt = PromptTemplate(
    template="""You are an expert in evaluating whether an AI-generated answer contains hallucinations.
Your task is to determine if the generated answer is faithful to the provided context and does not contain any information that is not supported by the context.

A hallucination occurs when:
1. The answer contains information that is not present in the provided context
2. The answer contradicts information in the context
3. The answer makes up facts, numbers, or details not found in the context
4. The answer draws conclusions that go beyond what the context supports

Evaluate the generated answer against the provided context and determine if there are any hallucinations.
Output your answer in JSON format, using the following structure:
{{"hallucination": "yes"}} if the answer contains hallucinations, or {{"hallucination": "no"}} if it does not.

Context: {context}
Generated Answer: {generated_answer}
{format_instructions}
""",
    input_variables=["context", "generated_answer"],
    partial_variables={
        "format_instructions": parser.get_format_instructions()
    },
)

# Hallucination í‰ê°€ ì²´ì¸
hallucination_chain = hallucination_prompt | llm | parser

def query_rag_system(user_query):
    """RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    # retriever ì´ˆê¸°í™”
    print("ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì¤‘...")
    retriever = get_retriever()
    
    # ì‚¬ìš©ì ì¿¼ë¦¬ë¡œ ê´€ë ¨ ë¬¸ì„œë“¤ ê²€ìƒ‰
    print(f"\nì‚¬ìš©ì ì¿¼ë¦¬: {user_query}")
    print("ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
    retrieved_docs = retriever.invoke(user_query)
    
    print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(retrieved_docs)}")
    
    relevant_chunks = []
    
    # ê° ê²€ìƒ‰ëœ ë¬¸ì„œì— ëŒ€í•´ ê´€ë ¨ì„± í‰ê°€
    for i, doc in enumerate(retrieved_docs):
        print(f"\n--- ë¬¸ì„œ {i+1} ê´€ë ¨ì„± í‰ê°€ ---")
        chunk_content = doc.page_content
        print(f"ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {chunk_content[:100]}...")
        
        # ê´€ë ¨ì„± í‰ê°€
        relevance_result = relevance_chain.invoke({
            "user_query": user_query, 
            "retrieved_chunk": chunk_content
        })
        print(f"ê´€ë ¨ì„± í‰ê°€ ê²°ê³¼: {relevance_result}")
        
        if relevance_result.get('relevance') == 'yes':
            relevant_chunks.append(chunk_content)
            print("-> ê´€ë ¨ì„± ìˆìŒ. ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€ë¨.")
        else:
            print("-> ê´€ë ¨ì„± ì—†ìŒ. ì œì™¸ë¨.")
    
    # ê´€ë ¨ì„± ìˆëŠ” ì²­í¬ë“¤ë¡œ ë‹µë³€ ìƒì„±
    if relevant_chunks:
        print(f"\n--- ë‹µë³€ ìƒì„± ---")
        print(f"ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œ ê°œìˆ˜: {len(relevant_chunks)}")
        
        # ëª¨ë“  ê´€ë ¨ ì²­í¬ë¥¼ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        combined_context = "\n\n".join(relevant_chunks)
        
        answer_response = answer_generation_chain.invoke({
            "user_query": user_query,
            "context": combined_context
        })
        print(f"ìƒì„±ëœ ë‹µë³€: {answer_response}")
        
        # Hallucination í‰ê°€
        print(f"\n--- Hallucination í‰ê°€ ---")
        hallucination_result = hallucination_chain.invoke({
            "context": combined_context,
            "generated_answer": answer_response.get('answer', '')
        })
        print(f"Hallucination í‰ê°€ ê²°ê³¼: {hallucination_result}")
        
        if hallucination_result.get('hallucination') == 'yes':
            print("âš ï¸  ê²½ê³ : ìƒì„±ëœ ë‹µë³€ì— Hallucinationì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("ğŸ“ ë‹µë³€ì„ ì‹ ì¤‘í•˜ê²Œ ê²€í† í•´ì£¼ì„¸ìš”.")
        else:
            print("âœ… Hallucinationì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        return answer_response
    else:
        print("\nê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {"answer": "ì œê³µëœ ë¬¸ì„œë“¤ì—ì„œ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

# ìƒ˜í”Œ ì‹¤í–‰
if __name__ == "__main__":
    # ìƒ˜í”Œ ì¿¼ë¦¬ë“¤ (ê´€ë ¨ì„± ìˆëŠ” ê²ƒê³¼ ì—†ëŠ” ê²ƒ ëª¨ë‘ í¬í•¨)
    sample_queries = [
        # AI/ML ê´€ë ¨ (ê´€ë ¨ì„± ìˆìŒ)
        "What is prompt engineering?",
        "How do AI agents work?",
        "What are adversarial attacks on LLMs?",
        
        # ì™„ì „íˆ ë‹¤ë¥¸ ì£¼ì œë“¤ (ê´€ë ¨ì„± ì—†ìŒ)
        "What is the capital of France?",
        "How to cook pasta?",
        "What are the basic guitar chords?",
        "How to calculate compound interest?"
    ]
    
    for query in sample_queries:
        print("=" * 80)
        result = query_rag_system(query)
        print("=" * 80)
        print()
